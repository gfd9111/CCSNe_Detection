{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e07528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwpy.timeseries import TimeSeries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import torch\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98b621bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This part uses the example timeseries from s11.2--LS220_0.1kpc_sim100_SNR29.21.txt\n",
    "# to produce the strain\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Initialize an empty list to store the numbers\n",
    "strain = []\n",
    "double_column = True\n",
    "# Open the file in read mode\n",
    "with open('s11.2--LS220_0.1kpc_sim100_SNR29.21.txt', \"r\") as file:\n",
    "    # Iterate through each line in the file\n",
    "    for line in file:\n",
    "        # Convert each line to a float and append it to the list\n",
    "        try:\n",
    "            if double_column:\n",
    "                parts = line.strip().split()\n",
    "                number = float(parts[1]); # use only the second column for strain\n",
    "            else:\n",
    "                number = float(line.strip())\n",
    "            strain.append(number)\n",
    "        except ValueError:\n",
    "            # Handle any invalid values or exceptions\n",
    "            print(f\"Skipping invalid value: {line.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b9906a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qgram(strain):\n",
    "    \"\"\"\n",
    "    Compute the Q-transform of the input strain and return the computed spectrogram as an image.\n",
    "    Alternatively you could also save the image locally as a .png\n",
    "\n",
    "    Parameters:\n",
    "    - strain: a raw Python list contianing the strain timeseries\n",
    "\n",
    "    Returns:\n",
    "    - An image of type PIL.Image.Image\n",
    "    \"\"\"\n",
    "    \n",
    "    # build the gwpy timeseries, change to your own sampling rate\n",
    "    hdata = TimeSeries(strain, sample_rate=2**14)\n",
    "    # band pass filtering the signal\n",
    "    hdata_filtered = hdata.bandpass(100,2000) \n",
    "    # q-transform\n",
    "    hq = hdata_filtered.q_transform(qrange=(100,200), frange=(0, 1600),\n",
    "                                    tres=(2-0)/128, fres=(1600-0)/128, norm='Median', whiten=False)  \n",
    "    # flip the array up and down so the frequency axis goes up\n",
    "    hq_array = np.flipud(np.transpose(hq.value))\n",
    "    # convert to uint8\n",
    "    hq_rescale = 255 * (hq_array - np.min(hq_array))/(np.max(hq_array) - np.min(hq_array)) # rescale to 0 and 255\n",
    "    # convert to image\n",
    "    hq_image = Image.fromarray(hq_rescale.astype(np.uint8))\n",
    "    \n",
    "    # could save the image locally here if wish\n",
    "    \n",
    "    return hq_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae03db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_category(prediction_array, threshold=0.4):\n",
    "    \"\"\"\n",
    "    Converts the prediction array to categories 'noise' or 'signal' using a threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - prediction_array (np.ndarray): The array of probabilities, they sum up to 1\n",
    "    - threshold (float): The threshold to classify as 'signal'. Default is 0.4.\n",
    "\n",
    "    Returns:\n",
    "    - List of categories: 'noise' or 'signal' for each prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    is_signal = prediction_array >= threshold\n",
    "\n",
    "    categories = np.where(is_signal, 'signal', 'noise')\n",
    "    \n",
    "    return categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c15cc8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image: Image.Image):\n",
    "    \"\"\"\n",
    "    Preprocesses a PIL image for testing according to the specified transformations.\n",
    "\n",
    "    Parameters:\n",
    "    - image (PIL.Image.Image): Input image to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Processed image ready for ONNX inference.\n",
    "    \"\"\"\n",
    "    # Define the transformation pipeline for testing\n",
    "    transform = v2.Compose([\n",
    "        v2.Resize((224, 224)),  # Resize image to 224x224\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),  # Convert to tensor, scales between [0, 1]\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ResNet18 parameters\n",
    "    ])\n",
    "\n",
    "    # Apply transformation to the image\n",
    "    image_tensor = transform(image)\n",
    "\n",
    "    # Convert torch.Tensor to numpy array with the correct shape for ONNX (NCHW format)\n",
    "    image_np = image_tensor.unsqueeze(0).numpy()  # Add batch dimension (1, 3, 224, 224)\n",
    "\n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26d3622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Probability for 'signal and 'noise': [0.00414355 0.99585646]\n",
      "Model Prediction: signal\n"
     ]
    }
   ],
   "source": [
    "# load the onnx model\n",
    "onnx_model = onnx.load(\"CCSNe_QNet_24Jan.onnx\")\n",
    "#onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# create inference session\n",
    "session = ort.InferenceSession(\"CCSNe_QNet_24Jan.onnx\")\n",
    "\n",
    "# get q-transform output\n",
    "qgram = get_qgram(strain)\n",
    "# pre-process the image\n",
    "input_img = preprocess_image(qgram)\n",
    "\n",
    "# CNN prediction\n",
    "input_name = session.get_inputs()[0].name\n",
    "result = session.run(None, {input_name: input_img})\n",
    "\n",
    "# Output the prediction\n",
    "category = 'signal' if result[0][0][1] > 0.4 else 'noise'\n",
    "\n",
    "print(\"Prediction Probability for 'signal and 'noise':\", result[0][0])\n",
    "print(\"Model Prediction:\", category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
